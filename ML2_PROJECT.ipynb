{"cells":[{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"tOXuPJZ4Qynr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9K7gmPw6uCPt"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf \n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras import layers\n","from keras.layers import Conv2D\n","from keras.layers import AveragePooling2D\n","from keras.layers import Flatten\n","from keras.layers import MaxPool2D\n","from keras.layers import Input\n","from keras.layers import BatchNormalization\n","from keras.models import Model\n","from keras.regularizers import l2\n","from keras import losses\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","import keras.backend as K\n","from keras.callbacks import LearningRateScheduler\n","from keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5637,"status":"ok","timestamp":1674985721157,"user":{"displayName":"Gianmarco Lodi","userId":"16526540830447781806"},"user_tz":-60},"id":"idqg4Ely315M","outputId":"b98d4c00-10cc-4ab1-ff6a-c7963f06292e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-cv\n","  Downloading keras_cv-0.4.1-py3-none-any.whl (615 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.8/615.8 KB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-cv) (21.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras-cv) (1.3.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from keras-cv) (4.8.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from keras-cv) (2022.6.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-cv) (3.0.9)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (4.64.1)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (0.1.8)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (2.25.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (3.19.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (7.1.2)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (1.12.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (1.21.6)\n","Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (0.3.6)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (5.10.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (5.4.8)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (1.0.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->keras-cv) (2.2.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras-cv) (3.11.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras-cv) (4.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (2.10)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.58.0)\n","Installing collected packages: keras-cv\n","Successfully installed keras-cv-0.4.1\n","You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n"]}],"source":["!pip install keras-cv\n","import tensorflow_datasets as tfds\n","import keras_cv\n","from keras_cv.layers import AugMix, CutMix, MixUp, GridMask\n","from tensorflow.keras.optimizers import Adam, SGD\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LbqZ3tPvAd_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674985848407,"user_tz":-60,"elapsed":16773,"user":{"displayName":"Gianmarco Lodi","userId":"16526540830447781806"}},"outputId":"b0532e25-8b1f-4c8c-ca88-b813c7e78def"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"uSiyYPjq_vcT"},"source":["## Data loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DzDYMYa1e_6O"},"outputs":[],"source":["# Change the path according to your specific GDrive\n","!unzip -u -q \"/content/drive/MyDrive/Machine Learning II/cifar10_1000.zip\" "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLZWY-2mZYQZ"},"outputs":[],"source":["size = '1000'           # Sizes: 1000  2000  3000  4000  original\n","aug_factor = 4          # Factors: 0.25  0.67  1  1.5  2  3  4\n","technique = \"augmix\"    # Techniques: cutmix  augmix  mixup  gridmask  baseline"]},{"cell_type":"code","source":["# Setting constant variables and seed\n","\n","ds_name = \"cifar10_\" + size\n","img_height = img_width = 32\n","batch_size = 128\n","AUTOTUNE = tf.data.AUTOTUNE\n","np.random.seed(42)"],"metadata":{"id":"XUWzsB6FdThD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1373,"status":"ok","timestamp":1674995192145,"user":{"displayName":"Gianmarco Lodi","userId":"16526540830447781806"},"user_tz":-60},"id":"BVcob9fAhkTN","outputId":"1eef84ce-914b-4852-d52d-67ce5436acfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 10000 files belonging to 10 classes.\n","Using 9000 files for training.\n","Found 10000 files belonging to 10 classes.\n","Using 1000 files for validation.\n","Found 10000 files belonging to 10 classes.\n"]}],"source":["# Loading datasets from GDrive directory\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  f\"/content/{ds_name}/train\",\n","  validation_split=0.1,\n","  subset=\"training\",\n","  seed=30,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size,\n","  label_mode=\"categorical\")\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  f\"/content/{ds_name}/train\",\n","  validation_split=0.1,\n","  subset=\"validation\",\n","  seed=30,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size,\n","  label_mode=\"categorical\")\n","\n","test_ds = tf.keras.utils.image_dataset_from_directory(\n","  f\"/content/{ds_name}/test\",\n","  seed=30,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size,\n","  label_mode=\"categorical\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"putP8Hm92GYw"},"outputs":[],"source":["# FUNCTIONS\n","\n","def ds_to_np(dataset):\n","    '''\n","    Transform a tf dataset in a numpy array, splitting X values from Y labels\n","    '''\n","    ds_np = np.array(list(dataset.unbatch().as_numpy_iterator()), dtype=object)\n","    flat_ds = np.asarray([x for x in ds_np])\n","    np.random.shuffle(flat_ds)\n","    img_ds = flat_ds[:,0]\n","    lbl_ds = flat_ds[:,1]\n","    X = np.asarray([img for img in img_ds], dtype='float32')\n","    Y = np.asarray([lbl for lbl in lbl_ds], dtype='float32')\n","    return X, Y\n","    \n","def visualize_dataset(dataset, title):\n","    '''\n","    Visualize 9 random images from a given dataset\n","    '''\n","    plt.figure(figsize=(12, 12)).suptitle(title, fontsize=18)\n","    for i, samples in enumerate(iter(dataset.take(9))):\n","        images = samples[0]\n","        plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[0].numpy().astype(\"uint8\"))\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","# Preprocessing for data augmentation\n","def to_dict(image, label):\n","    return {\"images\": image, \"labels\": label}\n","\n","def preprocess_for_model(inputs):\n","    images, labels = inputs[\"images\"], inputs[\"labels\"]\n","    images = tf.cast(images, tf.float32)\n","    return images, labels\n","\n","def data_augmentation(inputs, technique):\n","    return inputs.map(to_dict, num_parallel_calls=AUTOTUNE).map(lambda x: technique(x)).map(preprocess_for_model)\n","\n","# Combining source dataset with the augmented part\n","def prepare_combined_dataset(train_ds, augmentation_size, technique):\n","    '''\n","    :param train_ds: Starting dataset\n","    :param augmentation_size: Choose the augmentation factor among [0.25, 0.67, 1, 1.5, 2, 3, 4] \n","        e.g. 0.25 means that 25% of the given dataset will be augmented, resulting in a 125% bigger combined dataset\n","    :param technique: Choose a technique among 'cutmix', 'augmix', 'mixup', 'gridmask'\n","    :return the augmented subset and the full combined one.\n","    \n","    Performing augmentation and concatenating augmented dataset with starting dataset\n","    \n","    '''\n","    train_size = train_ds.cardinality().numpy()\n","    if augmentation_size < 1:\n","        subset_to_aug = train_ds.take(augmentation_size * train_size)   \n","        train_ds_aug = data_augmentation(subset_to_aug, technique)\n","    elif augmentation_size == 1.5:\n","        train_ds_aug_int = data_augmentation(train_ds, technique)\n","        subset_to_aug = train_ds.take(0.5 * train_size)   \n","        train_ds_aug_dec = data_augmentation(subset_to_aug, technique)\n","        train_ds_aug = train_ds_aug_int.concatenate(train_ds_aug_dec)\n","    else:\n","        train_ds_aug = data_augmentation(train_ds, technique)\n","        for _ in range(augmentation_size-1):\n","            train_ds_aug1 = data_augmentation(train_ds, technique)\n","            train_ds_aug = train_ds_aug.concatenate(train_ds_aug1)\n","\n","    train_ds_combined = train_ds.concatenate(train_ds_aug)\n","    return train_ds_aug, train_ds_combined\n","    \n","    "]},{"cell_type":"markdown","source":["## Setting Data Augmentation"],"metadata":{"id":"2z_7MXU2Pw9P"}},{"cell_type":"code","source":["techniques = {\n","    'cutmix': keras_cv.layers.CutMix(),\n","    'augmix': keras_cv.layers.AugMix((0,255)),\n","    'mixup': keras_cv.layers.MixUp(),\n","    'gridmask': keras_cv.layers.GridMask()\n","}"],"metadata":{"id":"GKlusJVHPv_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zy2aA2PT2Kje","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674995200307,"user_tz":-60,"elapsed":3045,"user":{"displayName":"Gianmarco Lodi","userId":"16526540830447781806"}},"outputId":"19faa88c-c349-490a-e0dd-a9a1494a561c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Batches augmented: 284\n","Batches not augmented: 71\n","Batches combined: 355\n"]}],"source":["# Performing data augmentation only if not 'baseline' \n","if technique != 'baseline':\n","    sub_aug, comb_ds = prepare_combined_dataset(train_ds, aug_factor, techniques[technique])\n","    print('Batches augmented:', sub_aug.cardinality().numpy())\n","    print('Batches not augmented:', train_ds.cardinality().numpy())\n","    print('Batches combined:', comb_ds.cardinality().numpy())\n","else:\n","    print('Batches in train set:', train_ds.cardinality().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KTnJf9vyBj5"},"outputs":[],"source":["# Transforming tensorflow dataset in numpy arrays\n","if technique == 'baseline':\n","    X_train, Y_train = ds_to_np(train_ds) \n","\n","else:\n","    X_train, Y_train = ds_to_np(comb_ds)\n","\n","X_val, Y_val = ds_to_np(val_ds)\n","X_test, Y_test = ds_to_np(test_ds)"]},{"cell_type":"markdown","metadata":{"id":"9uDGEJrCbHVa"},"source":["## ResNet20 and CIFAR-10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZq4aILxxIGt"},"outputs":[],"source":["# Defining a class for handling cifar10 data\n","class CIFAR10Data(object):\n","\n","    def __init__(self, x_train, y_train, x_val, y_val, x_test, y_test):\n","         self.x_train = x_train\n","         self.y_train = y_train\n","         self.x_val = x_val\n","         self.y_val = y_val\n","         self.x_test = x_test\n","         self.y_test = y_test\n","         \n","         self.classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","         print('CIFAR10 Training data shape:', self.x_train.shape)\n","         print('CIFAR10 Training label shape', self.y_train.shape)\n","         print('CIFAR10 Validation data shape', self.x_val.shape)\n","         print('CIFAR10 Validation label shape', self.y_val.shape)\n","         print('CIFAR10 Test data shape', self.x_test.shape)\n","         print('CIFAR10 Test label shape', self.y_test.shape)\n","\n","\n","    def get_data(self, subtract_mean=True, output_shape=None):\n","        num_classes = len(self.classes)\n","        x_train = self.x_train\n","        x_val = self.x_val\n","        x_test = self.x_test\n","\n","        x_train = x_train.astype('float16')\n","        y_train = self.y_train\n","\n","        x_val = x_val.astype('float16')\n","        y_val = self.y_val\n","\n","        x_test = x_test.astype('float16')\n","        y_test = self.y_test\n","\n","\n","        # normalization: subtract the mean value\n","        if subtract_mean:\n","            mean_image = np.mean(x_train, axis=0)\n","            x_train -= mean_image\n","            x_val -= mean_image\n","            x_test -= mean_image\n","\n","        return x_train, y_train, x_val, y_val, x_test, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSWKDlxCv5IQ"},"outputs":[],"source":["def conv2d_bn(x, filters, kernel_size, weight_decay=.0, strides=(1, 1)):\n","    layer = Conv2D(filters=filters,\n","                   kernel_size=kernel_size,\n","                   strides=strides,\n","                   padding='same',\n","                   use_bias=False,\n","                   kernel_regularizer=l2(weight_decay)\n","                   )(x)\n","    layer = BatchNormalization()(layer)\n","    return layer\n","\n","\n","def conv2d_bn_relu(x, filters, kernel_size, weight_decay=.0, strides=(1, 1)):\n","    layer = conv2d_bn(x, filters, kernel_size, weight_decay, strides)\n","    layer = Activation('relu')(layer)\n","    return layer\n","\n","\n","def ResidualBlock(x, filters, kernel_size, weight_decay, downsample=True):\n","    if downsample:\n","        # residual_x = conv2d_bn_relu(x, filters, kernel_size=1, strides=2)\n","        residual_x = conv2d_bn(x, filters, kernel_size=1, strides=2)\n","        stride = 2\n","    else:\n","        residual_x = x\n","        stride = 1\n","    residual = conv2d_bn_relu(x,\n","                              filters=filters,\n","                              kernel_size=kernel_size,\n","                              weight_decay=weight_decay,\n","                              strides=stride,\n","                              )\n","    residual = conv2d_bn(residual,\n","                         filters=filters,\n","                         kernel_size=kernel_size,\n","                         weight_decay=weight_decay,\n","                         strides=1,\n","                         )\n","    out = layers.add([residual_x, residual])\n","    out = Activation('relu')(out)\n","    return out\n","\n","\n","def ResNet18(classes, input_shape, weight_decay=1e-4):\n","    input = Input(shape=input_shape)\n","    x = input\n","    x = conv2d_bn_relu(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, strides=(1, 1))\n","\n","    # # conv 2\n","    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    # # conv 3\n","    x = ResidualBlock(x, filters=128, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n","    x = ResidualBlock(x, filters=128, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    # # conv 4\n","    x = ResidualBlock(x, filters=256, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n","    x = ResidualBlock(x, filters=256, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    # # conv 5\n","    x = ResidualBlock(x, filters=512, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n","    x = ResidualBlock(x, filters=512, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    x = AveragePooling2D(pool_size=(4, 4), padding='valid')(x)\n","    x = Flatten()(x)\n","    x = Dense(classes, activation='softmax')(x)\n","    model = Model(input, x, name='ResNet18')\n","    return model\n","\n","\n","def ResNetForCIFAR10(classes, name, input_shape, block_layers_num, weight_decay):\n","    input = Input(shape=input_shape)\n","    x = input\n","    x = conv2d_bn_relu(x, filters=16, kernel_size=(3, 3), weight_decay=weight_decay, strides=(1, 1))\n","\n","    # # conv 2\n","    for i in range(block_layers_num):\n","        x = ResidualBlock(x, filters=16, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    # # conv 3\n","    x = ResidualBlock(x, filters=32, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n","    for i in range(block_layers_num - 1):\n","        x = ResidualBlock(x, filters=32, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    # # conv 4\n","    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n","    for i in range(block_layers_num - 1):\n","        x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n","    x = AveragePooling2D(pool_size=(8, 8), padding='valid')(x)\n","    x = Flatten()(x)\n","    x = Dense(classes, activation='softmax')(x)\n","    model = Model(input, x, name=name)\n","    return model\n","\n","\n","def ResNet20ForCIFAR10(classes, input_shape, weight_decay):\n","    return ResNetForCIFAR10(classes, 'resnet20', input_shape, 3, weight_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsfZqWWyvgIh","executionInfo":{"status":"ok","timestamp":1674898192931,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alessandro Cortese","userId":"00367803873620696585"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc56e74f-f910-4de2-ca20-53a5345c4bad"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}],"source":["weight_decay = 1e-4\n","lr = 1e-1\n","num_classes = 10\n","resnet20 = ResNet20ForCIFAR10(input_shape=(32, 32, 3), classes=num_classes, weight_decay=weight_decay)\n","opt = optimizers.SGD(lr=lr, momentum=0.9, nesterov=False)\n","resnet20.compile(optimizer=opt,\n","                 loss=losses.CategoricalCrossentropy(), # label_smoothing = 0.1 for cutmix and augmix\n","                 metrics=['accuracy'])\n","#resnet20.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FheoU0zMv7U2"},"outputs":[],"source":["def plot_history(history):\n","    \"\"\"\n","    plot train epoch history and acc\n","    :param history: train history object returned by CIFAR10Solver.train()\n","    \"\"\"\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.xlabel('epoch')\n","    plt.ylabel('Loss value')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    plt.xlabel('epoch')\n","    plt.ylabel('acc value')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","\n","\n","class CIFAR10Solver(object):\n","    \"\"\"\n","    A CIFAR10Solver encapsulates all the logic nessary for training cifar10 classifiers.The train model is defined\n","    outside, you must pass it to init().\n","    The solver train the model, plot loss and aac history, and test on the test data.\n","    Example usage might look something like this.\n","    model = MyAwesomeModel(opt=SGD, losses='categorical_crossentropy',  metrics=['acc'])\n","    model.compile(...)\n","    model.summary()\n","    solver = CIFAR10Solver(model)\n","    history = solver.train()\n","    plotHistory(history)\n","    solver.test()\n","    \"\"\"\n","\n","    def __init__(self, model, data):\n","        \"\"\"\n","        :param model: A model object conforming to the API described above\n","        :param data:  A tuple of training, validation and test data from CIFAR10Data\n","        \"\"\"\n","        self.model = model\n","        self.X_train, self.Y_train, self.X_val, self.Y_val, self.X_test, self.Y_test = data\n","\n","    def __on_epoch_end(self, epoch, logs=None):\n","        print(K.eval(self.model.optimizer.lr))\n","\n","    def train(self, epochs=200, batch_size=128, data_augmentation=True, callbacks=None):\n","        if data_augmentation:\n","            # datagen\n","            datagen = ImageDataGenerator(\n","                featurewise_center=False,  # set input mean to 0 over the dataset\n","                samplewise_center=False,  # set each sample mean to 0\n","                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","                samplewise_std_normalization=False,  # divide each input by its std\n","                zca_whitening=False,  # apply ZCA whitening\n","                # rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n","                width_shift_range=4,  # randomly shift images horizontally (fraction of total width)\n","                height_shift_range=4,  # randomly shift images vertically (fraction of total height)\n","                horizontal_flip=True,  # randomly flip images\n","                vertical_flip=False,  # randomly flip images\n","            )\n","            # (std, mean, and principal components if ZCA whitening is applied).\n","            # datagen.fit(x_train)\n","            print('Training model with (light) data augmentation...')\n","            train_gen = datagen.flow(self.X_train, self.Y_train, batch_size=batch_size)\n","            history = self.model.fit_generator(generator=train_gen,\n","                                               epochs=epochs,\n","                                               callbacks=callbacks,\n","                                               validation_data=(self.X_val, self.Y_val),\n","                                               )\n","        else:\n","            print('Training model without data augmentation...')\n","            history = self.model.fit(self.X_train, self.Y_train,\n","                                     batch_size=batch_size, epochs=epochs,\n","                                     callbacks=callbacks,\n","                                     validation_data=(self.X_val, self.Y_val),\n","                                     )\n","        return history\n","\n","    def test(self):\n","        loss, acc = self.model.evaluate(self.X_test, self.Y_test)\n","        print('test data loss:%.2f acc:%.4f' % (loss, acc))"]},{"cell_type":"markdown","metadata":{"id":"cj7DPmMHbKpb"},"source":["## Training and Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2094,"status":"ok","timestamp":1674898195017,"user":{"displayName":"Alessandro Cortese","userId":"00367803873620696585"},"user_tz":-60},"id":"sVmajh2-xZNn","outputId":"74375cb7-f3c5-45ab-e0ee-568f9bed45f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["CIFAR10 Training data shape: (18000, 32, 32, 3)\n","CIFAR10 Training label shape (18000, 10)\n","CIFAR10 Validation data shape (1000, 32, 32, 3)\n","CIFAR10 Validation label shape (1000, 10)\n","CIFAR10 Test data shape (10000, 32, 32, 3)\n","CIFAR10 Test label shape (10000, 10)\n"]}],"source":["# get data\n","cifar10_data = CIFAR10Data(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n","data = cifar10_data.get_data(subtract_mean=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hj-k2lxVv7lQ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1674837353813,"user_tz":-60,"elapsed":79162,"user":{"displayName":"Alessandro Cortese","userId":"00367803873620696585"}},"outputId":"453a2cc1-0658-4fbe-a7a9-52e98f10dab8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training model without data augmentation...\n","new lr:1.00e-01\n","Epoch 1/182\n","141/141 [==============================] - ETA: 0s - loss: 1.9681 - accuracy: 0.3022\n","Epoch 1: val_accuracy improved from -inf to 0.21800, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 14s 35ms/step - loss: 1.9681 - accuracy: 0.3022 - val_loss: 3.9221 - val_accuracy: 0.2180 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 2/182\n","139/141 [============================>.] - ETA: 0s - loss: 1.5635 - accuracy: 0.4564\n","Epoch 2: val_accuracy improved from 0.21800 to 0.28800, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 4s 30ms/step - loss: 1.5617 - accuracy: 0.4574 - val_loss: 2.8933 - val_accuracy: 0.2880 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 3/182\n","139/141 [============================>.] - ETA: 0s - loss: 1.3054 - accuracy: 0.5608\n","Epoch 3: val_accuracy improved from 0.28800 to 0.46700, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 4s 29ms/step - loss: 1.3037 - accuracy: 0.5613 - val_loss: 1.7635 - val_accuracy: 0.4670 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 4/182\n","139/141 [============================>.] - ETA: 0s - loss: 1.1284 - accuracy: 0.6276\n","Epoch 4: val_accuracy improved from 0.46700 to 0.50900, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 4s 30ms/step - loss: 1.1294 - accuracy: 0.6277 - val_loss: 1.6754 - val_accuracy: 0.5090 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 5/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.9868 - accuracy: 0.6859\n","Epoch 5: val_accuracy did not improve from 0.50900\n","141/141 [==============================] - 4s 28ms/step - loss: 0.9872 - accuracy: 0.6858 - val_loss: 1.9516 - val_accuracy: 0.4760 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 6/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.8546 - accuracy: 0.7426\n","Epoch 6: val_accuracy improved from 0.50900 to 0.54600, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 4s 30ms/step - loss: 0.8558 - accuracy: 0.7420 - val_loss: 2.1930 - val_accuracy: 0.5460 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 7/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.7697 - accuracy: 0.7765\n","Epoch 7: val_accuracy did not improve from 0.54600\n","141/141 [==============================] - 4s 28ms/step - loss: 0.7701 - accuracy: 0.7763 - val_loss: 2.4345 - val_accuracy: 0.4430 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 8/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.8243\n","Epoch 8: val_accuracy did not improve from 0.54600\n","141/141 [==============================] - 4s 29ms/step - loss: 0.6494 - accuracy: 0.8242 - val_loss: 2.2156 - val_accuracy: 0.5240 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 9/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.5831 - accuracy: 0.8522\n","Epoch 9: val_accuracy did not improve from 0.54600\n","141/141 [==============================] - 4s 29ms/step - loss: 0.5835 - accuracy: 0.8522 - val_loss: 3.2894 - val_accuracy: 0.4990 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 10/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.5130 - accuracy: 0.8826\n","Epoch 10: val_accuracy improved from 0.54600 to 0.57700, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 6s 40ms/step - loss: 0.5131 - accuracy: 0.8825 - val_loss: 2.1528 - val_accuracy: 0.5770 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 11/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.4699 - accuracy: 0.9007\n","Epoch 11: val_accuracy did not improve from 0.57700\n","141/141 [==============================] - 4s 29ms/step - loss: 0.4708 - accuracy: 0.9001 - val_loss: 2.5885 - val_accuracy: 0.5720 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 12/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.9080\n","Epoch 12: val_accuracy did not improve from 0.57700\n","141/141 [==============================] - 4s 29ms/step - loss: 0.4612 - accuracy: 0.9081 - val_loss: 2.8172 - val_accuracy: 0.5480 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 13/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.9314\n","Epoch 13: val_accuracy improved from 0.57700 to 0.60700, saving model to /content/drive/MyDrive/Machine Learning II/best_models/cifar10_1000_1_augmix.h5\n","141/141 [==============================] - 4s 30ms/step - loss: 0.4081 - accuracy: 0.9307 - val_loss: 2.3052 - val_accuracy: 0.6070 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 14/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.4122 - accuracy: 0.9313\n","Epoch 14: val_accuracy did not improve from 0.60700\n","141/141 [==============================] - 4s 30ms/step - loss: 0.4139 - accuracy: 0.9307 - val_loss: 2.2869 - val_accuracy: 0.5900 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 15/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.9465\n","Epoch 15: val_accuracy did not improve from 0.60700\n","141/141 [==============================] - 4s 29ms/step - loss: 0.3840 - accuracy: 0.9463 - val_loss: 3.0120 - val_accuracy: 0.5510 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 16/182\n","139/141 [============================>.] - ETA: 0s - loss: 0.3924 - accuracy: 0.9431\n","Epoch 16: val_accuracy did not improve from 0.60700\n","141/141 [==============================] - 4s 28ms/step - loss: 0.3926 - accuracy: 0.9430 - val_loss: 2.7967 - val_accuracy: 0.5910 - lr: 0.1000\n","new lr:1.00e-01\n","Epoch 17/182\n"," 61/141 [===========>..................] - ETA: 2s - loss: 0.3677 - accuracy: 0.9579"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-1eef5f9e5a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10Solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m182\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-ec9bcae94f1b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, data_augmentation, callbacks)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model without data augmentation...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             history = self.model.fit(self.X_train, self.Y_train,\n\u001b[0m\u001b[1;32m     79\u001b[0m                                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                      \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def lr_scheduler(epoch):\n","    new_lr = lr\n","    if epoch <= 91:\n","        pass\n","    elif epoch > 91 and epoch <= 137:\n","        new_lr = lr * 0.1\n","    else:\n","        new_lr = lr * 0.01\n","    print('new lr:%.2e' % new_lr)\n","    return new_lr \n","\n","reduce_lr = LearningRateScheduler(lr_scheduler)\n","save_best = ModelCheckpoint('/content/drive/MyDrive/Machine Learning II/best_models/'+f\"{ds_name}_{aug_factor}_{technique}.h5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='max')\n","\n","\n","solver = CIFAR10Solver(resnet20, data)\n","history = solver.train(epochs=182, batch_size=128, data_augmentation=False, callbacks=[reduce_lr, save_best])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJFm-vz0rN6C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674660740863,"user_tz":-60,"elapsed":2440,"user":{"displayName":"Alessandro Cortese","userId":"00367803873620696585"}},"outputId":"5c0695f1-a353-4fb9-e928-7208438ac69b"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 6ms/step - loss: 1.2217 - accuracy: 0.8072\n","test data loss:1.22 acc:0.8072\n"]}],"source":["# TEST IN DISTRIBUTION\n","solver.model = keras.models.load_model(f\"/content/drive/MyDrive/Machine Learning II/best_models/{ds_name}_{aug_factor}_{technique}.h5\")\n","solver.test()"]},{"cell_type":"markdown","source":["### Out-of distribution testing"],"metadata":{"id":"GgI8F063gj9R"}},{"cell_type":"code","source":["# LOAD MODEL\n","solver = CIFAR10Solver(resnet20, data)\n"],"metadata":{"id":"5Qjm1BwlenAy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### CIFAR-10C - Mean Robust Accuracy"],"metadata":{"id":"erslkKqcOoTn"}},{"cell_type":"code","source":["import os\n","\n","y_test_ood = np.load(\"/content/drive/MyDrive/Machine Learning II/labels.npy\")\n","y_test_ood = keras.utils.to_categorical(y_test_ood, num_classes)\n","acc_ood_tot = 0\n","for corruption in os.listdir(\"/content/drive/MyDrive/Machine Learning II/CIFAR-10-C\"):\n","    print(f\"------{corruption}------\\n\")\n","    x_test_ood = np.load(\"/content/drive/MyDrive/Machine Learning II/CIFAR-10-C\" + \"/\" + corruption)\n","    loss, acc_ood = solver.model.evaluate(x_test_ood, y_test_ood)\n","    acc_ood_tot += acc_ood\n","\n","\n","print(\"Mean Robust Accuracy: \", acc_ood_tot/len(os.listdir(\"/content/drive/MyDrive/Machine Learning II/CIFAR-10-C\")))\n","\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVC_4gz6pxxK","executionInfo":{"status":"ok","timestamp":1674898510667,"user_tz":-60,"elapsed":312969,"user":{"displayName":"Alessandro Cortese","userId":"00367803873620696585"}},"outputId":"04bc3ff7-39b4-4a08-9451-a868e77b0188"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1563/1563 [==============================] - 15s 5ms/step - loss: 3.0762 - accuracy: 0.5407\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.9506 - accuracy: 0.5543\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.3996 - accuracy: 0.5073\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.5338 - accuracy: 0.4998\n","1563/1563 [==============================] - 10s 6ms/step - loss: 3.9009 - accuracy: 0.4403\n","1563/1563 [==============================] - 8s 5ms/step - loss: 4.0023 - accuracy: 0.4352\n","1563/1563 [==============================] - 16s 10ms/step - loss: 4.1967 - accuracy: 0.4328\n","1563/1563 [==============================] - 12s 8ms/step - loss: 3.5084 - accuracy: 0.4937\n","1563/1563 [==============================] - 10s 6ms/step - loss: 3.4406 - accuracy: 0.4734\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.6841 - accuracy: 0.4419\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.8172 - accuracy: 0.5648\n","1563/1563 [==============================] - 9s 6ms/step - loss: 4.8430 - accuracy: 0.3427\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.6052 - accuracy: 0.4764\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.9076 - accuracy: 0.5530\n","1563/1563 [==============================] - 9s 6ms/step - loss: 2.8196 - accuracy: 0.5701\n","1563/1563 [==============================] - 14s 9ms/step - loss: 2.9930 - accuracy: 0.5468\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.8617 - accuracy: 0.4691\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.0781 - accuracy: 0.5393\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.8641 - accuracy: 0.5703\n","Mean Robust Accuracy:  0.4974631588709982\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1XM2__oonC1ZftEp_taJrNaDnmhjdxpWY","timestamp":1674898594288},{"file_id":"18gWgihqLfHJQzqmjg26wWnE4cc-SR26Z","timestamp":1674641521018},{"file_id":"1ZTLxT2ZeD85V9OLMVdR0R9xpGWKCc9oC","timestamp":1673631939134}],"collapsed_sections":["9uDGEJrCbHVa","lhChQ0V1ui3U"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}